{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_experiments_latest (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FORKaBA-8GKa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from random import sample\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Distance between 2 red tokens: 1\n",
        "Count number of red tokens: 2\n",
        "Find token that appears maximum time: 3\n",
        "Compute sequence length: 4\n",
        "Palindrome Sequence: 5\n",
        "Sorted Sequence: 6\n",
        "Sum: 7\n",
        "MAx: 8\n",
        "Min: 9\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def Generate_data(vocab , problem_id , max_seq_length = 512, number_data_points = 100000):\n",
        "\n",
        "  '''This function generates the data based on our inputs\n",
        "\n",
        "  vocab: vaocabulary of chars we are working with\n",
        "  max_seq_length: max sequence length our single input can be of\n",
        "  number_data_points: number of data points we want to generate\n",
        "  problem_id: id of the problem for which data has to be generated'''\n",
        "\n",
        "  data = {}\n",
        "\n",
        "  #Generating for problem 1\n",
        "  if(problem_id == 1):\n",
        "    \n",
        "    print('**************GENERATING DATA FOR PROBLEM 1 *************\\n')\n",
        "\n",
        "    indices = [[i, j] for i in range(max_seq_length) for j in range(i+1, max_seq_length)]\n",
        "\n",
        "    def create_sequence_and_lables(indices):\n",
        "        sequence = tf.reduce_sum(tf.one_hot(indices, depth=max_seq_length, dtype='int64'), axis=0)\n",
        "        label = indices[1] - indices[0]\n",
        "        return sequence, label\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(indices)\n",
        "    dataset = dataset.shuffle(buffer_size=1024, reshuffle_each_iteration=False)\n",
        "    dataset = dataset.map(create_sequence_and_lables)\n",
        "\n",
        "\n",
        "    train_size = int(0.8 * len(indices))\n",
        "    train_dataset, test_dataset = dataset.take(train_size), dataset.skip(train_size)\n",
        "\n",
        "\n",
        "    train_dataset = train_dataset.batch(64, drop_remainder = True)\n",
        "    test_dataset = test_dataset.batch(64, drop_remainder = True)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "  #generating for problem 2\n",
        "  if(problem_id == 2):\n",
        "    print('**************GENERATING DATA FOR PROBLEM 2 *************\\n')\n",
        "\n",
        "\n",
        "    def int_to_sequence(i):\n",
        "      return tf.convert_to_tensor(list(map(int, (format(i.numpy(), 'b')))))\n",
        "\n",
        "    def map_int_to_sequence(i):\n",
        "      sequence = tf.py_function(int_to_sequence, [i], tf.int32)\n",
        "      label = tf.reduce_sum(sequence)\n",
        "      # Adding 1 to differentiate between padding value and token ids\n",
        "      return tf.add(sequence, 1), label\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(tf.range(100000))\n",
        "    dataset = dataset.map(map_int_to_sequence, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    train_size = int(0.8 * number_data_points)\n",
        "    train_dataset, test_dataset = dataset.take(train_size), dataset.skip(train_size)\n",
        "\n",
        "    train_dataset = train_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "    test_dataset = test_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "\n",
        "  '''data for problem 3'''\n",
        "  if(problem_id == 3):\n",
        "\n",
        "      print('**************GENERATING DATA FOR PROBLEM 3 *************\\n')\n",
        "\n",
        "      '''filling current i token in place of maximum # of 1 or 0 in the binary epresentation of i'''\n",
        "    \n",
        "      def make_data(i):\n",
        "        \n",
        "        b = format(i,'b')\n",
        "        num_one = len([1 for char in b if char == '1'])\n",
        "        num_zero = len([1 for char in b if char == '0'])\n",
        "\n",
        "        if(num_zero > num_one):\n",
        "          point = [vocab[i%len(vocab)] if char == '0' else vocab[((max_seq_length - len(b)) + index)%len(vocab)] for index,char in enumerate(b)]\n",
        "\n",
        "        else:\n",
        "          point = [vocab[i%len(vocab)] if char == '1' else vocab[((max_seq_length - len(b)) + index)%len(vocab)] for index,char in enumerate(b)]\n",
        "\n",
        "\n",
        "        return tf.convert_to_tensor(point,'string')\n",
        "        \n",
        "\n",
        "      def gen_data(i):\n",
        "        sequence = tf.py_function(make_data, [i], 'string')\n",
        "        label = tf.gather(vocab, i%len(vocab))\n",
        "        return sequence,label\n",
        "\n",
        "      dataset = tf.data.Dataset.from_tensor_slices(tf.range(number_data_points))\n",
        "\n",
        "      dataset = dataset.map(gen_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "      dataset = dataset.shuffle(buffer_size=1024, reshuffle_each_iteration=False)\n",
        "\n",
        "\n",
        "      train_size = int(0.8 * number_data_points)\n",
        "      train_dataset, test_dataset = dataset.take(train_size), dataset.skip(train_size)\n",
        "\n",
        "      train_dataset = train_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "      test_dataset = test_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "\n",
        "\n",
        "      return train_dataset, test_dataset\n",
        "\n",
        "  '''Data for problem 4'''\n",
        "  if(problem_id == 4):\n",
        "\n",
        "      print('**************GENERATING DATA FOR PROBLEM 4 *************\\n')\n",
        "\n",
        "      indices = [[0, j] for j in range(1, max_seq_length)]\n",
        "\n",
        "      def create_sequence_and_lables(indices):\n",
        "        sequence = tf.reduce_sum(tf.one_hot(tf.range(indices[0],indices[1]), depth=max_seq_length), axis=0)\n",
        "        label = indices[1] - indices[0]\n",
        "        return sequence, label\n",
        "\n",
        "      dataset = tf.data.Dataset.from_tensor_slices(indices)\n",
        "      dataset = dataset.shuffle(buffer_size=1024, reshuffle_each_iteration=False)\n",
        "      dataset = dataset.map(create_sequence_and_lables)\n",
        "\n",
        "\n",
        "      train_size = int(0.8 * len(indices))\n",
        "      train_dataset, test_dataset = dataset.take(train_size), dataset.skip(train_size)\n",
        "\n",
        "\n",
        "      train_dataset = train_dataset.batch(64)\n",
        "      test_dataset = test_dataset.batch(64)\n",
        "\n",
        "      return train_dataset, test_dataset\n",
        "\n",
        "  '''data for problem 5'''\n",
        "  if(problem_id == 5):\n",
        "\n",
        "    print('**************GENERATING DATA FOR PROBLEM 5 *************\\n')\n",
        "\n",
        "\n",
        "    '''if i is even data point will be palindrome else non palindrome'''\n",
        "    def make_palindrome(i):\n",
        "      '''if len of binary representation of i is even then even lenght palindrome else odd length palindrome'''\n",
        "      if(i%2 == 0):\n",
        "          b = format(i,'b')\n",
        "          l_b = len(b)\n",
        "          b = '0'*(max_seq_length - len(b)) + b\n",
        "          indices = [index%len(vocab) for index,char in enumerate(b) if char == '1']\n",
        "          if(l_b %2 == 0):\n",
        "            point = [vocab[i] for i in indices] + [vocab[i] for i in indices[: : -1]]\n",
        "\n",
        "          else:\n",
        "            point = [vocab[i] for i in indices] + [vocab[l_b]] + [vocab[i] for i in indices[: : -1]]\n",
        "      else:\n",
        "          b = format(i,'b')\n",
        "          l_b = len(b)\n",
        "          b = '0'*(max_seq_length - len(b)) + b\n",
        "          indices = [index%len(vocab) for index,char in enumerate(b) if char == '1']\n",
        "          point = [vocab[i] for i in indices] + [vocab[i] for i in [x*(x+4)%len(vocab) for x in indices]]\n",
        "\n",
        "      return tf.convert_to_tensor(point,'string')\n",
        "\n",
        "    def gen_data(i):\n",
        "        sequence = tf.py_function(make_palindrome, [i], 'string')\n",
        "\n",
        "        if(i %2 == 0):\n",
        "          label = 1\n",
        "        else:\n",
        "          label = 0\n",
        "        return sequence,label\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(tf.range(1,number_data_points))\n",
        "    dataset = dataset.map(gen_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(buffer_size=1024, reshuffle_each_iteration=False)\n",
        "\n",
        "    train_size = int(0.8 * number_data_points)\n",
        "    train_dataset, test_dataset = dataset.take(train_size), dataset.skip(train_size)\n",
        "\n",
        "    train_dataset = train_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "    test_dataset = test_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "\n",
        "  if(problem_id == 6):\n",
        "\n",
        "    print('**************GENERATING DATA FOR PROBLEM 6 *************\\n')\n",
        "\n",
        "\n",
        "    def make_sort_data(j):\n",
        "\n",
        "      start = j\n",
        "      b = format(start, 'b')\n",
        "      s = len([1 for char in format(start, 'b') if char == '1'])\n",
        "      m = 26\n",
        "      num = [s]\n",
        "      elem = j%67\n",
        "\n",
        "      for i in range(elem):\n",
        "        a = len([1 for char in format(start,'b') if char == '0'])\n",
        "        s = len([1 for char in format(start, 'b') if char == '1'])\n",
        "\n",
        "        c = s+a\n",
        "\n",
        "\n",
        "        next = (a*num[-1] + c) % m\n",
        "\n",
        "        if(j % 2 == 0):\n",
        "\n",
        "          #preparing sort data\n",
        "          if(next >= num[-1]):\n",
        "            num.append(next)\n",
        "\n",
        "            start = num[-1]\n",
        "          else:\n",
        "            start = next\n",
        "\n",
        "        else:\n",
        "            #prepraing unsort data\n",
        "            num.append(next)\n",
        "            start = num[-1]\n",
        "\n",
        "      return tf.convert_to_tensor(list(map(lambda x: vocab[x] ,num)), 'string')\n",
        "\n",
        "    def gen_sort_data(i):\n",
        "\n",
        "        sequence = tf.py_function(make_sort_data, [i], 'string')\n",
        "\n",
        "\n",
        "        if(i %2 == 0):\n",
        "          label = 1\n",
        "        else:\n",
        "          label = 0\n",
        "\n",
        "        return sequence,label\n",
        "\n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices(tf.range(number_data_points))\n",
        "\n",
        "    dataset = dataset.map(gen_sort_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.shuffle(buffer_size=1024, reshuffle_each_iteration=False)\n",
        "\n",
        "    train_size = int(0.8 * number_data_points)\n",
        "    train_dataset, test_dataset = dataset.take(train_size), dataset.skip(train_size)\n",
        "\n",
        "    train_dataset = train_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "    test_dataset = test_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "\n",
        "  if(problem_id == 7 or problem_id == 8 or problem_id == 9):\n",
        "\n",
        "    print('**************GENERATING DATA FOR PROBLEM 7/8/9 *************\\n')\n",
        "\n",
        "\n",
        "    def make_number_data(i):\n",
        "      return tf.convert_to_tensor([index%len(vocab) for index,char in enumerate('0'*(max_seq_length - len(format(i,'b'))) + format(i,'b')) if char == '1'],'int64')\n",
        "\n",
        "    def gen_data(i):\n",
        "\n",
        "      sequence = tf.py_function(make_number_data, [i], 'int64')\n",
        "\n",
        "      if(problem_id == 7):\n",
        "        label = tf.reduce_sum(sequence)\n",
        "      elif(problem_id == 8):\n",
        "        label = tf.reduce_max(sequence)\n",
        "      else:\n",
        "        label = tf.reduce_min(sequence)\n",
        "\n",
        "      return sequence, label\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(tf.range(2**27,2**27 + number_data_points))\n",
        "    dataset = dataset.map(gen_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(buffer_size=1024, reshuffle_each_iteration=False)\n",
        "\n",
        "    train_size = int(0.8 * number_data_points)\n",
        "    train_dataset, test_dataset = dataset.take(train_size), dataset.skip(train_size)\n",
        "\n",
        "    train_dataset = train_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "    test_dataset = test_dataset.padded_batch(512, padded_shapes=((None,), ()))\n",
        "\n",
        "\n",
        "    return train_dataset, test_dataset\n"
      ],
      "metadata": {
        "id": "ejbg2QojABB-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_3 = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
        "vocab_4 = list(range(10))\n",
        "train_dataset, test_dataset = Generate_data(vocab_3, 1, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxp0oGXPk5Tv",
        "outputId": "bb28c51c-bac6-4138-d9b3-9827c4b3dcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 1 *************\n",
            "\n",
            "(<tf.Tensor: shape=(64, 512), dtype=int64, numpy=\n",
            "array([[0, 1, 0, ..., 0, 0, 0],\n",
            "       [0, 1, 0, ..., 0, 0, 0],\n",
            "       [0, 1, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 1, 0, ..., 0, 0, 0],\n",
            "       [0, 1, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
            "array([454, 112, 201, 487, 437, 269, 383, 482, 442, 163,   5, 145, 204,\n",
            "       142, 197, 509, 250, 147, 293, 253, 468,  58, 470, 282, 508,   6,\n",
            "       168,  21, 124, 163, 488, 447, 341, 479,  58, 128, 484, 380, 265,\n",
            "       344,  76, 278,  54, 182, 463, 131, 237,  80,  16,   6, 116, 185,\n",
            "       261,  96, 293,  59,  38,  30, 348, 270, 275, 134, 377, 402],\n",
            "      dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = Generate_data(vocab_3, 2, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN8QM3rz8VGV",
        "outputId": "05436194-bc79-423d-cd96-3cbb99420b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 2 *************\n",
            "\n",
            "(<tf.Tensor: shape=(512, 9), dtype=int32, numpy=\n",
            "array([[1, 0, 0, ..., 0, 0, 0],\n",
            "       [2, 0, 0, ..., 0, 0, 0],\n",
            "       [2, 1, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [2, 2, 2, ..., 2, 1, 2],\n",
            "       [2, 2, 2, ..., 2, 2, 1],\n",
            "       [2, 2, 2, ..., 2, 2, 2]], dtype=int32)>, <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
            "array([0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4, 1, 2, 2, 3, 2, 3,\n",
            "       3, 4, 2, 3, 3, 4, 3, 4, 4, 5, 1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4,\n",
            "       3, 4, 4, 5, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6, 1, 2,\n",
            "       2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5, 2, 3, 3, 4, 3, 4, 4, 5,\n",
            "       3, 4, 4, 5, 4, 5, 5, 6, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5,\n",
            "       5, 6, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, 1, 2, 2, 3,\n",
            "       2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4,\n",
            "       4, 5, 4, 5, 5, 6, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,\n",
            "       3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, 2, 3, 3, 4, 3, 4,\n",
            "       4, 5, 3, 4, 4, 5, 4, 5, 5, 6, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6,\n",
            "       5, 6, 6, 7, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, 4, 5,\n",
            "       5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8, 1, 2, 2, 3, 2, 3, 3, 4,\n",
            "       2, 3, 3, 4, 3, 4, 4, 5, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5,\n",
            "       5, 6, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6, 3, 4, 4, 5,\n",
            "       4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4,\n",
            "       4, 5, 4, 5, 5, 6, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,\n",
            "       3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, 4, 5, 5, 6, 5, 6,\n",
            "       6, 7, 5, 6, 6, 7, 6, 7, 7, 8, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5,\n",
            "       4, 5, 5, 6, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, 3, 4,\n",
            "       4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, 4, 5, 5, 6, 5, 6, 6, 7,\n",
            "       5, 6, 6, 7, 6, 7, 7, 8, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6,\n",
            "       6, 7, 4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8, 4, 5, 5, 6,\n",
            "       5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8, 5, 6, 6, 7, 6, 7, 7, 8, 6, 7,\n",
            "       7, 8, 7, 8, 8, 9], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = Generate_data(vocab_3, 3, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4yt_4Cn_52o",
        "outputId": "96d90a21-55a6-4921-c7e9-41673fa1d87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 3 *************\n",
            "\n",
            "(<tf.Tensor: shape=(512, 11), dtype=string, numpy=\n",
            "array([[b'I', b'J', b'Y', ..., b'Q', b'Y', b''],\n",
            "       [b'F', b'L', b'M', ..., b'', b'', b''],\n",
            "       [b'B', b'B', b'L', ..., b'B', b'', b''],\n",
            "       ...,\n",
            "       [b'C', b'C', b'C', ..., b'', b'', b''],\n",
            "       [b'D', b'D', b'', ..., b'', b'', b''],\n",
            "       [b'X', b'J', b'K', ..., b'X', b'X', b'']], dtype=object)>, <tf.Tensor: shape=(512,), dtype=string, numpy=\n",
            "array([b'Y', b'F', b'B', b'G', b'G', b'D', b'O', b'X', b'J', b'V', b'O',\n",
            "       b'X', b'Y', b'Q', b'R', b'G', b'D', b'V', b'V', b'J', b'Y', b'Z',\n",
            "       b'V', b'E', b'X', b'Q', b'K', b'J', b'D', b'Z', b'T', b'H', b'A',\n",
            "       b'O', b'L', b'W', b'S', b'I', b'H', b'P', b'C', b'W', b'B', b'H',\n",
            "       b'I', b'R', b'L', b'E', b'C', b'W', b'Q', b'C', b'K', b'B', b'T',\n",
            "       b'B', b'R', b'C', b'U', b'C', b'S', b'U', b'R', b'H', b'H', b'D',\n",
            "       b'K', b'K', b'V', b'K', b'Z', b'V', b'H', b'K', b'N', b'G', b'R',\n",
            "       b'K', b'Q', b'S', b'E', b'L', b'D', b'T', b'C', b'B', b'T', b'U',\n",
            "       b'P', b'O', b'D', b'W', b'W', b'B', b'V', b'M', b'D', b'Z', b'D',\n",
            "       b'C', b'M', b'B', b'W', b'Y', b'A', b'M', b'J', b'Z', b'K', b'V',\n",
            "       b'A', b'V', b'O', b'F', b'U', b'C', b'J', b'M', b'F', b'F', b'O',\n",
            "       b'T', b'Q', b'G', b'E', b'X', b'R', b'O', b'I', b'D', b'A', b'N',\n",
            "       b'E', b'H', b'O', b'G', b'C', b'E', b'V', b'I', b'X', b'V', b'J',\n",
            "       b'X', b'P', b'E', b'V', b'J', b'E', b'S', b'E', b'Z', b'G', b'H',\n",
            "       b'Y', b'A', b'V', b'O', b'U', b'W', b'G', b'C', b'W', b'X', b'M',\n",
            "       b'B', b'R', b'I', b'S', b'V', b'Z', b'K', b'T', b'Z', b'S', b'U',\n",
            "       b'Z', b'N', b'D', b'I', b'U', b'D', b'N', b'N', b'Q', b'T', b'S',\n",
            "       b'O', b'E', b'Z', b'E', b'N', b'Y', b'M', b'U', b'F', b'V', b'Z',\n",
            "       b'E', b'W', b'Q', b'N', b'I', b'K', b'O', b'Z', b'C', b'Z', b'Q',\n",
            "       b'O', b'L', b'X', b'I', b'C', b'U', b'L', b'L', b'Z', b'X', b'T',\n",
            "       b'T', b'Y', b'J', b'T', b'U', b'X', b'P', b'Q', b'A', b'H', b'L',\n",
            "       b'M', b'D', b'A', b'Q', b'F', b'J', b'Y', b'Z', b'B', b'P', b'N',\n",
            "       b'S', b'E', b'V', b'Q', b'Y', b'L', b'I', b'A', b'V', b'G', b'M',\n",
            "       b'L', b'D', b'F', b'U', b'Z', b'I', b'C', b'X', b'H', b'W', b'T',\n",
            "       b'V', b'Q', b'C', b'D', b'I', b'P', b'N', b'A', b'N', b'D', b'T',\n",
            "       b'C', b'U', b'Q', b'X', b'G', b'G', b'K', b'S', b'N', b'N', b'V',\n",
            "       b'G', b'D', b'S', b'X', b'A', b'A', b'M', b'C', b'X', b'F', b'S',\n",
            "       b'I', b'E', b'K', b'N', b'V', b'M', b'E', b'Q', b'E', b'E', b'M',\n",
            "       b'P', b'Y', b'O', b'U', b'O', b'M', b'Q', b'Y', b'J', b'A', b'M',\n",
            "       b'F', b'Y', b'V', b'O', b'X', b'L', b'X', b'K', b'P', b'Y', b'A',\n",
            "       b'X', b'B', b'S', b'T', b'Z', b'S', b'O', b'I', b'B', b'I', b'J',\n",
            "       b'Z', b'T', b'L', b'B', b'A', b'S', b'K', b'K', b'T', b'T', b'W',\n",
            "       b'L', b'U', b'B', b'O', b'F', b'O', b'N', b'V', b'R', b'I', b'U',\n",
            "       b'Y', b'U', b'L', b'P', b'G', b'G', b'I', b'F', b'J', b'M', b'P',\n",
            "       b'X', b'O', b'A', b'J', b'P', b'Q', b'V', b'L', b'P', b'V', b'X',\n",
            "       b'N', b'V', b'V', b'W', b'U', b'Y', b'H', b'F', b'N', b'D', b'S',\n",
            "       b'J', b'B', b'Q', b'X', b'U', b'J', b'B', b'W', b'U', b'V', b'O',\n",
            "       b'X', b'W', b'S', b'A', b'A', b'H', b'L', b'O', b'K', b'L', b'E',\n",
            "       b'A', b'U', b'V', b'R', b'Z', b'G', b'F', b'I', b'U', b'U', b'G',\n",
            "       b'Q', b'I', b'F', b'M', b'F', b'E', b'L', b'N', b'A', b'Q', b'W',\n",
            "       b'E', b'M', b'K', b'W', b'L', b'T', b'M', b'Q', b'E', b'S', b'B',\n",
            "       b'R', b'R', b'B', b'M', b'C', b'L', b'T', b'P', b'G', b'H', b'M',\n",
            "       b'C', b'Y', b'I', b'R', b'Q', b'X', b'L', b'B', b'I', b'Y', b'H',\n",
            "       b'O', b'E', b'Z', b'I', b'M', b'G', b'A', b'E', b'L', b'A', b'A',\n",
            "       b'F', b'Y', b'N', b'U', b'D', b'L', b'C', b'R', b'W', b'P', b'V',\n",
            "       b'M', b'R', b'P', b'I', b'M', b'O', b'Z', b'O', b'R', b'W', b'V',\n",
            "       b'K', b'I', b'U', b'C', b'D', b'X'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = Generate_data(vocab_3, 4, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1uzLe-G3U4I",
        "outputId": "08bbddb5-e377-460a-d070-d696dba104c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 4 *************\n",
            "\n",
            "(<tf.Tensor: shape=(64, 512), dtype=float32, numpy=\n",
            "array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
            "array([329, 376, 277, 475, 486, 175, 332,  14,  97, 223, 434, 276, 433,\n",
            "       229,  10, 487, 384, 303, 113, 305, 284, 427,  32, 425, 159, 213,\n",
            "       437,  70, 348, 304, 371, 115, 438, 356, 400, 450,  89, 235,   2,\n",
            "       311,  46, 155, 289,  94, 168, 386, 203, 123, 441,  56, 200, 185,\n",
            "       110,  53, 187, 117, 147, 183,  36, 162, 105, 217,  47,  17],\n",
            "      dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = Generate_data(vocab_3, 5, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9EfJGGFy6E1",
        "outputId": "1a7a0961-cb79-4bdf-8d56-53073b814c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 5 *************\n",
            "\n",
            "(<tf.Tensor: shape=(512, 20), dtype=string, numpy=\n",
            "array([[b'I', b'J', b'L', ..., b'', b'', b''],\n",
            "       [b'K', b'N', b'O', ..., b'', b'', b''],\n",
            "       [b'I', b'J', b'K', ..., b'', b'', b''],\n",
            "       ...,\n",
            "       [b'H', b'K', b'L', ..., b'', b'', b''],\n",
            "       [b'H', b'K', b'N', ..., b'', b'', b''],\n",
            "       [b'I', b'L', b'O', ..., b'', b'', b'']], dtype=object)>, <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
            "array([1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
            "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
            "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
            "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
            "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
            "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
            "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
            "       0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
            "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
            "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
            "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
            "       1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
            "       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
            "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
            "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
            "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
            "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
            "       0, 1, 0, 1, 0, 0], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = Generate_data(vocab_3, 6, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQWjL9ElmL3U",
        "outputId": "e30d0fb3-6bae-4b95-da81-a17b07e2fbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 6 *************\n",
            "\n",
            "(<tf.Tensor: shape=(512, 67), dtype=string, numpy=\n",
            "array([[b'F', b'J', b'W', ..., b'', b'', b''],\n",
            "       [b'H', b'K', b'Y', ..., b'', b'', b''],\n",
            "       [b'G', b'I', b'K', ..., b'', b'', b''],\n",
            "       ...,\n",
            "       [b'H', b'X', b'C', ..., b'', b'', b''],\n",
            "       [b'E', b'I', b'K', ..., b'', b'', b''],\n",
            "       [b'D', b'F', b'I', ..., b'', b'', b'']], dtype=object)>, <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
            "array([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
            "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
            "       0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
            "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
            "       1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
            "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
            "       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
            "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
            "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
            "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
            "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
            "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
            "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
            "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
            "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
            "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 1, 1], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = Generate_data(vocab_4, 7, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFFIE2c0AM-l",
        "outputId": "9be8ddac-9276-4da1-dc87-f3e79000b41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 7/8/9 *************\n",
            "\n",
            "(<tf.Tensor: shape=(512, 11), dtype=int64, numpy=\n",
            "array([[4, 2, 3, ..., 1, 0, 0],\n",
            "       [4, 2, 3, ..., 0, 0, 0],\n",
            "       [4, 2, 3, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [4, 1, 3, ..., 0, 0, 0],\n",
            "       [4, 2, 3, ..., 0, 0, 0],\n",
            "       [4, 1, 7, ..., 0, 0, 0]])>, <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([38, 30, 36, 37, 26, 28, 22, 40, 32, 12, 18, 28, 22,  4, 32, 31, 29,\n",
            "       31, 15, 32, 20, 18, 18, 36, 17, 29, 18, 16, 22, 27, 39, 23, 26, 23,\n",
            "       26, 34, 13, 23, 31, 36, 12, 24, 28, 24, 17, 22, 20, 27, 19, 15, 31,\n",
            "       31, 38, 27, 21, 23, 32, 19, 20, 25, 29, 29, 15, 37, 27, 20, 17, 27,\n",
            "       36, 38, 25, 21, 32, 48, 26, 22, 32, 34,  5, 29, 13, 28, 36, 31, 35,\n",
            "       24, 24, 32, 43, 40, 22, 14, 43, 37, 11, 31, 25, 26, 30, 26, 21, 19,\n",
            "       14, 28, 22, 46, 39, 12, 31, 19, 27, 19, 41, 34, 33, 36, 27, 40, 32,\n",
            "       19, 29, 33, 28, 22, 20, 27, 12, 21, 11, 25, 31, 23, 27, 36, 14, 29,\n",
            "       28, 35, 31, 10, 36, 21, 40, 48, 17, 33, 29, 24, 11, 40, 31, 30, 16,\n",
            "       22, 18, 31, 16, 18, 20, 44, 28, 28, 24, 37, 26, 46, 15, 24, 30, 33,\n",
            "       25, 31, 22, 21, 22, 13, 30, 40, 27, 23, 36, 28, 32, 29, 35, 35, 22,\n",
            "       25, 32, 29, 23, 35,  9, 15, 17, 49, 14, 13, 16, 29, 18, 15, 42, 24,\n",
            "       17, 32, 22, 21, 15, 30, 37, 43, 28, 14, 31, 25, 25, 18, 22, 30, 27,\n",
            "       28, 27,  9, 30, 33, 25,  5, 26, 23, 28, 25, 29, 39, 27, 27, 42, 24,\n",
            "       27, 30, 34, 23, 14, 23,  6, 23, 19, 39, 11, 16, 27, 41, 22, 18, 24,\n",
            "       28, 28,  8, 40, 36, 32, 24, 19, 15, 28, 32, 30, 19, 18, 14, 20, 38,\n",
            "       34, 27, 25,  9, 18, 15, 24, 17, 10, 25, 23, 26, 23, 25, 33, 30, 21,\n",
            "       30, 42, 29, 29, 27, 18, 41, 21, 30, 25, 32, 17, 32, 38, 21, 28, 26,\n",
            "       20, 30, 24, 29, 26, 20, 28, 22, 45, 21, 28, 16, 21,  8, 41, 34,  4,\n",
            "       36, 15, 37, 35, 27, 19, 20, 41, 22, 35, 20, 20, 33, 35, 30, 17, 18,\n",
            "       16, 34, 22, 17, 21, 17, 37, 16,  8, 31, 20, 44, 22, 28, 21, 27, 17,\n",
            "       44, 17, 34, 27, 24, 22, 26, 16, 38, 31, 23, 31, 29, 23, 24, 23, 20,\n",
            "       17, 20, 20, 39, 23, 33, 23, 23, 30, 13, 21, 22, 28, 18, 33, 19, 17,\n",
            "       19, 31, 36, 12, 35, 32, 20, 33, 31, 35, 24, 16, 23, 26, 20, 31, 43,\n",
            "       30, 36, 33, 19, 35, 47, 36, 29, 34, 22, 11, 38, 33, 37, 12, 31, 24,\n",
            "       25, 28, 15, 26, 19, 30, 18, 29,  9, 16, 27, 32, 32, 22, 32, 18, 20,\n",
            "       20, 32, 38, 33, 19, 22, 32, 35, 20, 27,  9, 20, 29, 36, 17, 41, 25,\n",
            "       13, 22, 29, 15, 41, 37, 36, 17, 39, 10, 24, 18, 28, 25, 18, 29, 32,\n",
            "       34, 34, 31, 24, 25, 20, 19, 17, 31, 24, 11, 21, 28, 13, 31, 33, 19,\n",
            "       29, 21, 27, 36, 29, 26, 27, 42, 27, 17, 39, 15, 39, 22, 17, 14, 30,\n",
            "       33, 21])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = Generate_data(vocab_4, 8, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHoNsrozIY9z",
        "outputId": "8380e1a4-ee7f-4059-c569-1321b7d5dd8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 7/8/9 *************\n",
            "\n",
            "(<tf.Tensor: shape=(512, 11), dtype=int64, numpy=\n",
            "array([[4, 5, 6, ..., 0, 0, 0],\n",
            "       [4, 2, 4, ..., 0, 0, 0],\n",
            "       [4, 3, 4, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [4, 1, 3, ..., 0, 0, 0],\n",
            "       [4, 1, 3, ..., 0, 1, 0],\n",
            "       [4, 2, 5, ..., 0, 0, 0]])>, <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([6, 4, 9, 8, 9, 9, 9, 8, 9, 8, 9, 7, 9, 9, 8, 9, 4, 7, 9, 9, 6, 9,\n",
            "       7, 5, 8, 9, 9, 4, 9, 8, 7, 7, 8, 9, 9, 5, 8, 9, 8, 9, 7, 9, 8, 9,\n",
            "       9, 9, 7, 9, 8, 9, 6, 5, 9, 7, 8, 9, 8, 8, 8, 9, 9, 6, 7, 8, 9, 9,\n",
            "       9, 9, 7, 9, 9, 9, 9, 8, 9, 9, 9, 8, 8, 7, 9, 8, 9, 9, 9, 9, 9, 9,\n",
            "       7, 8, 7, 9, 9, 6, 4, 8, 9, 8, 8, 8, 6, 4, 9, 8, 9, 9, 9, 9, 8, 9,\n",
            "       9, 9, 8, 9, 8, 9, 8, 8, 9, 8, 9, 9, 8, 9, 8, 6, 9, 8, 8, 6, 9, 8,\n",
            "       8, 4, 9, 9, 6, 7, 9, 9, 9, 8, 7, 7, 9, 9, 9, 8, 6, 8, 9, 9, 9, 9,\n",
            "       9, 6, 9, 9, 9, 9, 9, 9, 7, 7, 8, 9, 9, 4, 9, 9, 8, 7, 9, 9, 5, 9,\n",
            "       9, 8, 5, 8, 9, 6, 9, 9, 4, 9, 9, 9, 9, 8, 5, 7, 8, 9, 8, 9, 9, 7,\n",
            "       9, 9, 9, 8, 8, 9, 9, 9, 9, 8, 9, 8, 9, 9, 7, 5, 9, 9, 6, 9, 9, 5,\n",
            "       5, 9, 9, 9, 9, 8, 4, 5, 7, 8, 4, 7, 8, 8, 8, 9, 7, 8, 9, 8, 9, 8,\n",
            "       9, 9, 9, 9, 9, 9, 4, 9, 8, 8, 5, 9, 9, 8, 7, 9, 9, 7, 7, 7, 8, 9,\n",
            "       7, 9, 8, 9, 9, 7, 9, 8, 6, 9, 9, 9, 8, 7, 8, 6, 8, 9, 7, 7, 7, 8,\n",
            "       9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 6, 8, 9, 9, 9, 9, 7, 8, 8, 9, 6,\n",
            "       9, 9, 9, 9, 8, 4, 9, 9, 9, 8, 8, 5, 9, 7, 7, 9, 9, 9, 8, 8, 9, 9,\n",
            "       9, 9, 8, 9, 8, 9, 9, 8, 9, 7, 9, 9, 6, 9, 6, 9, 8, 9, 9, 8, 6, 6,\n",
            "       9, 8, 8, 9, 9, 9, 9, 8, 7, 6, 9, 7, 9, 4, 9, 9, 9, 8, 5, 8, 5, 9,\n",
            "       9, 8, 6, 8, 6, 9, 7, 5, 9, 6, 9, 9, 8, 9, 9, 8, 8, 8, 9, 7, 9, 4,\n",
            "       9, 8, 8, 9, 9, 9, 8, 9, 5, 6, 9, 9, 8, 8, 9, 8, 7, 9, 8, 7, 9, 6,\n",
            "       4, 8, 8, 9, 9, 6, 9, 9, 8, 6, 9, 7, 6, 8, 8, 8, 7, 8, 6, 8, 8, 6,\n",
            "       7, 9, 8, 9, 8, 4, 9, 8, 9, 9, 9, 8, 8, 8, 9, 8, 5, 8, 9, 8, 8, 9,\n",
            "       8, 9, 5, 6, 9, 8, 9, 8, 8, 4, 9, 9, 9, 8, 9, 7, 9, 9, 9, 8, 9, 9,\n",
            "       7, 9, 8, 9, 9, 9, 8, 9, 7, 4, 6, 8, 6, 9, 4, 9, 9, 8, 6, 8, 9, 9,\n",
            "       8, 7, 8, 8, 8, 9])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = Generate_data(vocab_4, 9, 512)\n",
        "for batch in train_dataset:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7tfyLyyccLV",
        "outputId": "8c64197b-18a0-4b8d-c312-fc6e41c88c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 7/8/9 *************\n",
            "\n",
            "(<tf.Tensor: shape=(512, 11), dtype=int64, numpy=\n",
            "array([[4, 2, 3, ..., 0, 0, 0],\n",
            "       [4, 3, 6, ..., 0, 0, 0],\n",
            "       [4, 3, 5, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [4, 3, 6, ..., 0, 0, 0],\n",
            "       [4, 1, 3, ..., 0, 0, 0],\n",
            "       [4, 2, 3, ..., 0, 0, 0]])>, <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([2, 3, 3, 1, 1, 0, 0, 4, 1, 0, 0, 1, 4, 0, 0, 3, 0, 2, 1, 1, 0, 0,\n",
            "       0, 4, 1, 3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "       0, 0, 1, 0, 3, 4, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 1, 1, 1, 0, 1, 0,\n",
            "       1, 0, 4, 0, 2, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
            "       1, 1, 0, 4, 0, 1, 0, 1, 3, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 0,\n",
            "       1, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 2,\n",
            "       2, 2, 0, 0, 1, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 1, 4, 2, 0, 2, 4, 0,\n",
            "       0, 0, 1, 0, 4, 2, 0, 1, 0, 2, 0, 0, 0, 3, 0, 0, 1, 1, 0, 0, 0, 2,\n",
            "       1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 3, 1, 1,\n",
            "       1, 1, 4, 2, 0, 1, 1, 1, 2, 2, 2, 0, 1, 3, 1, 2, 0, 2, 0, 1, 0, 2,\n",
            "       0, 3, 1, 0, 4, 0, 1, 4, 0, 0, 3, 0, 2, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
            "       1, 3, 0, 0, 1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 3, 1, 0, 2, 1, 0, 0,\n",
            "       4, 1, 1, 1, 0, 2, 0, 1, 0, 0, 2, 1, 1, 3, 1, 2, 1, 1, 2, 1, 2, 3,\n",
            "       0, 1, 1, 1, 0, 2, 1, 0, 1, 0, 0, 0, 1, 3, 0, 1, 1, 1, 0, 2, 1, 0,\n",
            "       1, 0, 2, 1, 1, 4, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 3, 0, 0, 1, 1, 1, 2, 0, 1, 0,\n",
            "       0, 0, 0, 1, 0, 1, 0, 0, 1, 2, 0, 1, 2, 1, 0, 2, 0, 1, 0, 3, 0, 4,\n",
            "       0, 1, 0, 0, 0, 2, 4, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
            "       1, 0, 0, 4, 1, 1, 1, 0, 1, 0, 0, 0, 1, 2, 0, 4, 1, 1, 0, 2, 0, 4,\n",
            "       0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 2, 2, 0,\n",
            "       0, 4, 1, 0, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 3, 2,\n",
            "       0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
            "       0, 0, 1, 0, 0, 4, 4, 2, 0, 0, 0, 3, 0, 0, 0, 3, 0, 1, 1, 0, 1, 0,\n",
            "       0, 0, 3, 0, 1, 0])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelling"
      ],
      "metadata": {
        "id": "xnCLWKMKrvX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, Input\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "kIgkl8TCxFnZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_3 = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
        "vocab_4 = list(range(10))\n",
        "train_dataset, test_dataset = Generate_data(vocab_3, 1, 512)\n",
        "frst_batch = None\n",
        "for batch in train_dataset:\n",
        "  frst_batch = batch\n",
        "  print(batch)\n",
        "  break\n",
        "\n",
        "for batch in train_dataset:\n",
        "  if(batch[0].shape[0] != 64):\n",
        "    print('here')\n",
        "frst_batch[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2zjLcpEvTfF",
        "outputId": "29e81078-62e8-47b2-cd4e-65d5ce3c4d8e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************GENERATING DATA FOR PROBLEM 1 *************\n",
            "\n",
            "(<tf.Tensor: shape=(64, 512), dtype=int64, numpy=\n",
            "array([[1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 1, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 1, 0, ..., 0, 0, 0],\n",
            "       [0, 1, 0, ..., 0, 0, 0],\n",
            "       [0, 1, 0, ..., 0, 0, 0]])>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
            "array([411,   7, 322, 219, 244,  19, 494, 490, 101, 129, 114,  21, 445,\n",
            "       313,  37,  23, 233, 178, 280, 193, 368, 115, 476, 497, 484, 186,\n",
            "       134, 227, 138,  83, 124, 147, 452, 237, 163, 165, 246, 264, 284,\n",
            "       215, 272, 422, 383, 322, 367, 472, 435, 407, 136, 198,  29, 197,\n",
            "         1,  46,  85, 401,  57, 156, 353, 161, 455, 326,  22, 348],\n",
            "      dtype=int32)>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'num_heads' : 1,\n",
        "    'num_layers': 1,\n",
        "    'emb_dim': 128,\n",
        "    'seq_length': 512,\n",
        "    'vocab_size': 2,\n",
        "    'head_size': 64, #size of single dense layer head\n",
        "    'pos_embedding': True, #True or False weather to learn positional embeddings\n",
        "    'agg_method': 'TOKEN' #one of TOKEN or SUM\n",
        "}\n"
      ],
      "metadata": {
        "id": "RsRk84_PMNQb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Encodings(tf.keras.layers.Layer):\n",
        "\n",
        "  '''\n",
        "    This class takes input tokens and return the embeddings with class token appended and positional embeddings added\n",
        "  '''\n",
        "\n",
        "  def __init__(self, config):\n",
        "\n",
        "    super().__init__()\n",
        "    self.embedding_dim = config['emb_dim']\n",
        "    self.seq_length = config['seq_length']\n",
        "    self.vocab_size = config['vocab_size']\n",
        "    self.pos_embedding_flag = config['pos_embedding']\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim, input_length = self.seq_length)\n",
        "    self.pos_embedding = Embedding(self.seq_length + 1, self.embedding_dim)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    batch_size = 64\n",
        "    self.class_tokens = Embedding(batch_size, self.embedding_dim)\n",
        "    self.class_tokens = self.class_tokens(tf.range(start=0, limit=batch_size, delta=1))\n",
        "\n",
        "\n",
        "  def call(self, batch):\n",
        "    embedding_out = tf.concat([self.embedding(batch), tf.expand_dims(self.class_tokens, axis=1)], axis=1)\n",
        "\n",
        "    if(self.pos_embedding_flag):\n",
        "      pos_embedding = self.pos_embedding(tf.range(start = 0, limit = self.seq_length + 1, delta=1))\n",
        "      embedding_out = embedding_out + pos_embedding\n",
        "\n",
        "\n",
        "    return embedding_out\n"
      ],
      "metadata": {
        "id": "v2SKv58_qAtL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = Encodings(config)(frst_batch[0])\n",
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnOEzPFFy0GD",
        "outputId": "960e42e9-fb08-4a18-ccdb-87cac0244546"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 513, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "\n",
        "  '''\n",
        "    This class implements the Attention layer mechanism and returns the attention output and attention scores for each attention head\n",
        "  '''\n",
        "\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_att_heads = config['num_heads']\n",
        "    self.attention_head_size = int(config['emb_dim'] / self.num_att_heads)\n",
        "    self.all_head_size = self.num_att_heads * self.attention_head_size\n",
        "\n",
        "    self.query = Dense(self.all_head_size)\n",
        "    self.key = Dense(self.all_head_size)\n",
        "    self.value = Dense(self.all_head_size)\n",
        "    self.out = Dense(config['emb_dim'])\n",
        "\n",
        "  def call(self, hidden_states):\n",
        "\n",
        "    #getting the query , key and value vectors\n",
        "    mixed_query_layer = self.query(hidden_states)\n",
        "    mixed_key_layer = self.key(hidden_states)\n",
        "    mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "    hidden_states_shape = tf.shape(hidden_states)\n",
        "\n",
        "    #Dividing query keay and value vectors between given number of attention heads\n",
        "    query_layer = tf.reshape(mixed_query_layer, shape = (hidden_states_shape[0], self.num_att_heads, \n",
        "                                 hidden_states_shape[1],\n",
        "                                 self.attention_head_size))\n",
        "    \n",
        "\n",
        "    key_layer = tf.reshape(mixed_key_layer, shape = (hidden_states_shape[0], self.num_att_heads, \n",
        "                                 hidden_states_shape[1],\n",
        "                                 self.attention_head_size))\n",
        "    \n",
        "    value_layer = tf.reshape(mixed_value_layer, shape = (hidden_states_shape[0], self.num_att_heads, \n",
        "                                 hidden_states_shape[1],\n",
        "                                 self.attention_head_size))\n",
        "    \n",
        "    #getting the attention scores\n",
        "    attention_scores = tf.matmul(query_layer, tf.transpose(key_layer, perm=[0,1,3,2]))\n",
        "\n",
        "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "\n",
        "    attention_probs = tf.nn.softmax(attention_scores, axis=-1)\n",
        "\n",
        "    #getting the attention output\n",
        "    context_layer = tf.matmul(attention_probs, value_layer)\n",
        "    context_layer = tf.reshape(context_layer, shape=( hidden_states_shape[0],\n",
        "                                                         hidden_states_shape[1],\n",
        "                                                         hidden_states_shape[2]))\n",
        "    \n",
        "    att_output = self.out(context_layer)\n",
        "\n",
        "    return att_output, attention_probs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1mG25p99N-vg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_output, att_scores = Attention(config)(embeddings)"
      ],
      "metadata": {
        "id": "W0od0ei9F0YL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_output.shape, att_scores.shape, np.sum(att_scores[0,0,54]) , att_output[:,0,:].shape, tf.math.reduce_sum(att_output[:,1:,:], axis = 1).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpYAdMkbGHdy",
        "outputId": "32e414e4-8384-44bf-8123-c6e7d8fb7cde"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 513, 128]),\n",
              " TensorShape([64, 1, 513, 513]),\n",
              " 1.0,\n",
              " TensorShape([64, 128]),\n",
              " TensorShape([64, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class _Model(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encodings = Encodings(config)\n",
        "    self.attention = Attention(config)\n",
        "    self.agg_method = config['agg_method']\n",
        "    self.head_dim = config['head_size']\n",
        "    self.head = Dense(self.head_dim)\n",
        "\n",
        "\n",
        "  def call(self, input):\n",
        "    op = self.encodings(input)\n",
        "    att_op, att_scores = self.attention(op)\n",
        "\n",
        "    if(self.agg_method == 'TOKEN'):\n",
        "      op = att_op[:,0,:]\n",
        "    else:\n",
        "      op = tf.math.reduce_sum(att_op[:, 1:, :], axis = 1)\n",
        "\n",
        "    op = self.head(op)\n",
        "\n",
        "\n",
        "    return op, att_scores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HtOIQVU4HaOc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "op, att_scores = _Model(config)(frst_batch[0])\n",
        "op.shape, att_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuL1PjSHN9GN",
        "outputId": "971d9e11-681c-4418-d49b-001d86007884"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 64]), TensorShape([64, 1, 513, 513]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (512)\n",
        "input = Input(input_shape)\n",
        "op, att_scores = _Model(config)(input)\n",
        "output = Dense(1, activation='linear')(op)\n",
        "\n",
        "model = Model(inputs = input, outputs=output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heTvNGRfQBIu",
        "outputId": "406cf5d0-9c95-4d77-ddd2-5c3ecae6bdb5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " private__model_1 (_Model)   ((64, 64),                140224    \n",
            "                              (64, 1, 513, 513))                 \n",
            "                                                                 \n",
            " dense_14 (Dense)            (64, 1)                   65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140,289\n",
            "Trainable params: 140,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= 'adam', loss='mean_squared_error', metrics = ['mean_squared_error'])\n",
        "model.fit(train_dataset, epochs = 1, validation_data = test_dataset, steps_per_epoch = len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRpX764IYMpw",
        "outputId": "9a35aa8d-37e1-4493-9e60-57d32b5eac2f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1635/1635 [==============================] - 42s 25ms/step - loss: 7458.4595 - mean_squared_error: 7458.4595 - val_loss: 42203.6289 - val_mean_squared_error: 42203.6289\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0839e8d290>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}